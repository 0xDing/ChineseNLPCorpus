# 预训练：（词向量or模型）

## BERT

1. 开源代码：https://github.com/google-research/bert
2. 模型下载：[**BERT-Base, Chinese**](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip): Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters



## ELMO

1. 开源代码：https://github.com/allenai/bilm-tf
2. 预训练的模型：https://allennlp.org/elmo

## 腾讯词向量

腾讯AI实验室公开的中文词向量数据集包含800多万中文词汇，其中每个词对应一个200维的向量。

- 下载地址：https://ai.tencent.com/ailab/nlp/embedding.html

